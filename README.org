* Second Mate
An open-source, mini imitation of [[https://copilot.github.com/][GitHub Copilot]] using *update:* [[https://huggingface.co/replit/replit-code-v1-3b][Replit Code 3B]] or  [[https://huggingface.co/EleutherAI/gpt-neo-2.7B][EleutherAI GPT-Neo-2.7B]] (via Huggingface Model Hub) for Emacs.

[[./assets/demo1.gif]]

* Setup
** Inference End / Backend
1. Set =device= to "cpu" or "cuda" in =serve/server.py=
2. The "priming" is currently done in Python. If you want, modify it to another language or turn it off (from subjective experience, priming seems to help).
3. Launch =serve/server.py=. This will launch a Flask app which will allow us to sample the model via REST API.

** Emacs
1. In =emacs/secondmate.el=, customize the URL in =secondmate-url= to the address the API is running on.
